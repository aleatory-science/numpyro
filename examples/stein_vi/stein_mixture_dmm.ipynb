{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Markov Model\n",
    "Based on \"Structured Inference Networks for Nonlinear State Space Models\" by Krishnan, Shalit and Sontag. (AAAI 2017)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.ops\n",
    "import jax.numpy as jnp\n",
    "from jax.experimental import stax\n",
    "import numpyro\n",
    "import numpyro.distributions as dist\n",
    "from numpyro.infer import SVI, ELBO, Stein\n",
    "from numpyro.infer.kernels import RBFKernel\n",
    "from numpyro.infer.guide import WrappedGuide\n",
    "from numpyro.optim import Adam\n",
    "from numpyro.examples.datasets import load_dataset, JSBCHORALES\n",
    "from tqdm import tqdm\n",
    "from numpyro.callbacks import Progbar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequences:  (32, 129, 4)\n",
      "Length min:  33 max:  120\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "init, get_batch = load_dataset(JSBCHORALES, batch_size=batch_size, convert_to_jax=True)\n",
    "ds_count, ds_indxs = init()\n",
    "seqs, seqs_rev, lengths = get_batch(0, ds_indxs)\n",
    "print(\"Sequences: \", seqs.shape)\n",
    "print(\"Length min: \", min(lengths), \"max: \", max(lengths))\n",
    "\n",
    "## %\n",
    "def batch_fun(step):\n",
    "    i = step % ds_count\n",
    "    epoch = step // ds_count\n",
    "    is_last = i == (ds_count - 1)\n",
    "    return get_batch(i, ds_indxs), {}, epoch, is_last"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Caskroom/miniconda/base/envs/numpyro-stein/lib/python3.8/site-packages/jax/lax/lax.py:5605: UserWarning: Explicitly requested dtype int requested in array is not available, and will be truncated to dtype int32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  warnings.warn(msg.format(dtype, fun_name , truncated_dtype))\n"
     ]
    },
    {
     "data": {
      "text/plain": "(32, 88)"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def _one_hot_chorales(seqs, num_nodes=88):\n",
    "    return jnp.sum(jnp.array((seqs[..., None] == jnp.arange(num_nodes + 1)), 'int'), axis=-2)[..., 1:]\n",
    "_one_hot_chorales(seqs[:, 0]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 4  5]\n",
      "  [ 3  4]\n",
      "  [ 2  3]\n",
      "  [ 1  2]\n",
      "  [ 0  0]]\n",
      "\n",
      " [[10 11]\n",
      "  [ 9 10]\n",
      "  [ 8  9]\n",
      "  [ 0  0]\n",
      "  [ 0  0]]]\n"
     ]
    }
   ],
   "source": [
    "def _reverse_padded(padded, lengths):\n",
    "    def _reverse_single(p, l):\n",
    "        new = jnp.zeros_like(p)\n",
    "        reverse = jnp.roll(p[::-1], l, axis=0)\n",
    "        return jax.ops.index_update(new, jax.ops.index[:], reverse)\n",
    "    return jax.vmap(_reverse_single)(padded, lengths)\n",
    "with jax.disable_jit():\n",
    "    print(_reverse_padded(jnp.array([[[1, 2], [2, 3], [3, 4], [4, 5]] +\n",
    "                                     [[0, 0]], [[8, 9],[9,10],[10,11]] + [[0,0]] * 2]), jnp.array([4, 3])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DMM Neural Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Emitter(hidden_dim1, hidden_dim2, out_dim):\n",
    "    return stax.serial(\n",
    "        stax.Dense(hidden_dim1), stax.Relu,\n",
    "        stax.Dense(hidden_dim2), stax.Relu,\n",
    "        stax.Dense(out_dim), stax.Sigmoid\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Transition(gate_hidden_dim, prop_mean_hidden_dim, out_dim):\n",
    "    gate_init_fun, gate_apply_fun = stax.serial(\n",
    "        stax.Dense(gate_hidden_dim), stax.Relu,\n",
    "        stax.Dense(out_dim), stax.Sigmoid\n",
    "    )\n",
    "\n",
    "    prop_mean_init_fun, prop_mean_apply_fun = stax.serial(\n",
    "        stax.Dense(prop_mean_hidden_dim), stax.Relu,\n",
    "        stax.Dense(out_dim)\n",
    "    )\n",
    "\n",
    "    mean_init_fun, mean_apply_fun = stax.Dense(out_dim)\n",
    "\n",
    "    stddev_init_fun, stddev_apply_fun = stax.serial(\n",
    "        stax.Relu, stax.Dense(out_dim),\n",
    "        stax.Softplus\n",
    "    )\n",
    "\n",
    "    def init_fun(rng, input_shape):\n",
    "        output_shape = input_shape[:-1] + (out_dim,)\n",
    "        k1, k2, k3, k4 = jax.random.split(rng, num=4)\n",
    "        _, gate_params = gate_init_fun(k1, input_shape)\n",
    "        prop_mean_output_shape, prop_mean_params = prop_mean_init_fun(k2, input_shape)\n",
    "        _, mean_params = mean_init_fun(k3, input_shape)\n",
    "        _, stddev_params = stddev_init_fun(k4, prop_mean_output_shape)\n",
    "        return (output_shape, output_shape), (gate_params, prop_mean_params, \n",
    "                                              mean_params, stddev_params)\n",
    "\n",
    "    def apply_fun(params, inputs, **kwargs):\n",
    "        gate_params, prop_mean_params, mean_params, stddev_params = params\n",
    "        gt = gate_apply_fun(gate_params, inputs)\n",
    "        ht = prop_mean_apply_fun(prop_mean_params, inputs)\n",
    "        mut = (1 - gt) * mean_apply_fun(mean_params, inputs) + gt * ht\n",
    "        sigmat = stddev_apply_fun(stddev_params, ht)\n",
    "        return mut, sigmat\n",
    "    \n",
    "    return init_fun, apply_fun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Combiner(hidden_dim, out_dim):\n",
    "    mean_init_fun, mean_apply_fun = stax.Dense(out_dim)\n",
    "\n",
    "    stddev_init_fun, stddev_apply_fun = stax.serial(\n",
    "        stax.Dense(out_dim),\n",
    "        stax.Softplus\n",
    "    )\n",
    "\n",
    "    def init_fun(rng, input_shape):\n",
    "        output_shape = input_shape[:-1] + (out_dim,)\n",
    "        k1, k2 = jax.random.split(rng, num=2)\n",
    "        _, mean_params = mean_init_fun(k1, input_shape)\n",
    "        _, stddev_params = stddev_init_fun(k2, input_shape)\n",
    "        return (output_shape, output_shape) , (mean_params, stddev_params)\n",
    "\n",
    "    def apply_fun(params, inputs, **kwargs):\n",
    "        mean_params, stddev_params = params\n",
    "        mut = mean_apply_fun(mean_params, inputs)\n",
    "        sigmat = stddev_apply_fun(stddev_params, inputs)\n",
    "        return mut, sigmat\n",
    "    return init_fun, apply_fun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GRU(hidden_dim, W_init=stax.glorot_normal()):\n",
    "    # Inspired by https://github.com/google/jax/pull/2298\n",
    "    input_update_init_fun, input_update_apply_fun = stax.Dense(hidden_dim)\n",
    "    input_reset_init_fun, input_reset_apply_fun = stax.Dense(hidden_dim)\n",
    "    input_output_init_fun, input_output_apply_fun = stax.Dense(hidden_dim)\n",
    "\n",
    "    def init_fun(rng, input_shape):\n",
    "        indv_input_shape = input_shape[1:]\n",
    "        output_shape = input_shape[:-1] + (hidden_dim,)\n",
    "        rng, k1, k2 = jax.random.split(rng, num=3)\n",
    "        hidden_update_w = W_init(k1, (hidden_dim, hidden_dim))\n",
    "        _, input_update_params = input_update_init_fun(k2, indv_input_shape)\n",
    "\n",
    "        rng, k1, k2 = jax.random.split(rng, num=3)\n",
    "        hidden_reset_w = W_init(k1, (hidden_dim, hidden_dim))\n",
    "        _, input_reset_params = input_reset_init_fun(k2, indv_input_shape)\n",
    "\n",
    "        rng, k1, k2 = jax.random.split(rng, num=3)\n",
    "        hidden_output_w = W_init(k1, (hidden_dim, hidden_dim))\n",
    "        _, input_output_params = input_output_init_fun(k2, indv_input_shape)\n",
    "\n",
    "        return output_shape, (hidden_update_w, input_update_params,\n",
    "                              hidden_reset_w, input_reset_params,\n",
    "                              hidden_output_w, input_output_params)\n",
    "    \n",
    "    def apply_fun(params, inputs, **kwargs):\n",
    "        (hidden_update_w, input_update_params,\n",
    "         hidden_reset_w, input_reset_params,\n",
    "         hidden_output_w, input_output_params) = params\n",
    "        inps, lengths, init_hidden = inputs\n",
    "\n",
    "        def apply_fun_single(prev_hidden, inp):\n",
    "            i, inpv = inp\n",
    "            inp_update = input_update_apply_fun(input_update_params, inpv)\n",
    "            hidden_update = jnp.dot(prev_hidden, hidden_update_w)\n",
    "            update_gate = stax.sigmoid(inp_update + hidden_update)\n",
    "            reset_gate = stax.sigmoid(input_reset_apply_fun(input_reset_params, inpv) +\n",
    "                                      jnp.dot(prev_hidden, hidden_reset_w))\n",
    "            output_gate = update_gate * prev_hidden + (1 - update_gate) * jnp.tanh(\n",
    "                input_output_apply_fun(input_output_params, inpv) + \n",
    "                jnp.dot(reset_gate * prev_hidden, hidden_output_w))\n",
    "            hidden = jnp.where((i < lengths)[:, None], output_gate, jnp.zeros_like(prev_hidden))\n",
    "            return hidden, hidden\n",
    "\n",
    "        return jax.lax.scan(apply_fun_single, init_hidden, (jnp.arange(inps.shape[0]), inps))\n",
    "    return init_fun, apply_fun"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probabilistic model and guide"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is a vectorized version based on https://github.com/pyro-ppl/pyro/blob/f73df6c1c20bc7b9164d79ce4217557d0aa8e396/examples/dmm/dmm.py#L192 by Martin Jankowiak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(seqs, seqs_rev, lengths, *,\n",
    "          latent_dim=100, emission_dim=100, transition_dim=200,\n",
    "          data_dim=88, gru_dim=400, annealing_factor=1.0):\n",
    "    batch_size, max_seq_length, *_ = seqs.shape\n",
    "    \n",
    "    transition = numpyro.module('transition', Transition(transition_dim, transition_dim, latent_dim),\n",
    "                                input_shape=(batch_size, latent_dim))\n",
    "    emitter = numpyro.module('emitter', Emitter(emission_dim, emission_dim, data_dim),\n",
    "                                input_shape=(batch_size, latent_dim))\n",
    "\n",
    "    z0 = numpyro.param('z0', jnp.zeros((batch_size, 1, latent_dim)))\n",
    "    ones = jnp.ones((batch_size, max_seq_length, latent_dim))\n",
    "\n",
    "    masks = jnp.repeat(jnp.expand_dims(jnp.arange(max_seq_length), axis=0), batch_size, axis=0) <\\\n",
    "            jnp.expand_dims(lengths, axis=-1)\n",
    "    with numpyro.plate('data', batch_size):\n",
    "        # NB: Mask is to avoid scoring 'z' using distribution at this point\n",
    "        z = numpyro.sample('z', dist.Normal(0.0, ones).mask(False).to_event(2))\n",
    "        z_shift = jnp.concatenate([z0, z[:, :-1, :]], axis=-2)\n",
    "        z_loc, z_scale = transition(z_shift)\n",
    "\n",
    "        with numpyro.handlers.scale(scale_factor=annealing_factor):\n",
    "            # Actually score 'z'\n",
    "            numpyro.sample('z_aux', dist.Normal(z_loc, z_scale).mask(jnp.expand_dims(masks, axis=-1))\n",
    "                                                               .to_event(2), obs=z)\n",
    "        \n",
    "        emission_probs = emitter(z)\n",
    "        oh_x = _one_hot_chorales(seqs)\n",
    "        numpyro.sample('obs_x', dist.Bernoulli(emission_probs).mask(jnp.expand_dims(masks, axis=-1))\n",
    "                                                              .to_event(2), obs=oh_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def guide(seqs, seqs_rev, lengths, *,\n",
    "          latent_dim=100, emission_dim=100, transition_dim=200,\n",
    "          data_dim=88, gru_dim=400, annealing_factor=1.0):\n",
    "    batch_size, max_seq_length, *_ = seqs.shape\n",
    "    seqs_rev = jnp.transpose(seqs_rev, axes=(1, 0, 2))\n",
    "    gru = numpyro.module('gru', GRU(gru_dim), input_shape=(max_seq_length, batch_size, data_dim))\n",
    "    combiner = numpyro.module('combiner', Combiner(gru_dim, latent_dim),\n",
    "                              input_shape=(batch_size, gru_dim))\n",
    "    \n",
    "    masks = jnp.repeat(jnp.expand_dims(jnp.arange(max_seq_length), axis=0), batch_size, axis=0) <\\\n",
    "        jnp.expand_dims(lengths, axis=-1)\n",
    "\n",
    "    h0 = numpyro.param('h0', jnp.zeros((batch_size, gru_dim)))\n",
    "    _, hs = gru((_one_hot_chorales(seqs_rev), lengths, h0))\n",
    "    hs = _reverse_padded(jnp.transpose(hs, axes=(1, 0, 2)), lengths)\n",
    "    z_loc, z_scale = combiner(hs)\n",
    "    with numpyro.plate('data', batch_size):\n",
    "        with numpyro.handlers.scale(scale_factor=annealing_factor):\n",
    "            numpyro.sample('z', dist.Normal(z_loc, z_scale).mask(jnp.expand_dims(masks, axis=-1)).to_event(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stochastic Variational Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "svi = SVI(model, guide, Adam(8e-4), ELBO())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SVI 1.3433e+05: 100%|██████████| 7/7 [01:07<00:00,  9.70s/it]\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 1\n",
    "rng_key = jax.random.PRNGKey(seed=142)\n",
    "state, loss = svi.train(rng_key, num_epochs * ds_count,\n",
    "                        callbacks=[Progbar()], batch_fun=batch_fun)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stein Variational Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "svgd = Stein(model, WrappedGuide(guide, reinit_hide_fn=lambda site: site['name'].endswith('$params')), Adam(8e-4), ELBO(), RBFKernel(), num_particles=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Stein 1.3842e+05: 100%|██████████| 7/7 [02:10<00:00, 18.70s/it]\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 1\n",
    "rng_key = jax.random.PRNGKey(seed=142)\n",
    "state, loss = svgd.train(rng_key, num_epochs * ds_count,\n",
    "                         callbacks=[Progbar()], batch_fun=batch_fun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}